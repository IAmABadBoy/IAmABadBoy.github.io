<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.0.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">
  <link rel="alternate" href="/atom.xml" title="oooo的博客" type="application/atom+xml">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '7.5.0',
    exturl: false,
    sidebar: {"position":"right","display":"post","offset":12,"onmobile":false},
    copycode: {"enable":false,"show_result":false,"style":null},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},
    path: '',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    sidebarPadding: 40
  };
</script>

  <meta name="description" content="oooo的博客">
<meta property="og:type" content="website">
<meta property="og:title" content="oooo的博客">
<meta property="og:url" content="http:&#x2F;&#x2F;yoursite.com&#x2F;index.html">
<meta property="og:site_name" content="oooo的博客">
<meta property="og:description" content="oooo的博客">
<meta property="og:locale" content="zh-CN">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://yoursite.com/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: true,
    isPost: false,
    isPage: false,
    isArchive: false
  };
</script>

  <title>oooo的博客</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">oooo的博客</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
        <p class="site-subtitle">副标题</p>
  </div>

  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>首页</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>归档</a>

  </li>
  </ul>

</nav>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/12/03/Multi-View-Stereo-by-Temporal-Nonparametric-Fusio/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="oooo">
      <meta itemprop="description" content="oooo的博客">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="oooo的博客">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2019/12/03/Multi-View-Stereo-by-Temporal-Nonparametric-Fusio/" class="post-title-link" itemprop="url">Multi-View_Stereo_by_Temporal_Nonparametric_Fusio</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2019-12-03 14:38:48 / 修改时间：20:55:27" itemprop="dateCreated datePublished" datetime="2019-12-03T14:38:48+08:00">2019-12-03</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB/" itemprop="url" rel="index">
                    <span itemprop="name">文章阅读</span>
                  </a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="文章结构"><a href="#文章结构" class="headerlink" title="文章结构"></a>文章结构</h2><blockquote>
<ul>
<li>Abstract</li>
<li>Introduction</li>
<li>Related Work</li>
<li>Methods</li>
<li>Experiments</li>
<li>Discussion and conclusion</li>
</ul>
</blockquote>
<h2 id="文章解读"><a href="#文章解读" class="headerlink" title="文章解读"></a>文章解读</h2><h3 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h3><p>&emsp;&emsp;我们提出了什么样的模型? </p>
<blockquote>
<p>我们提出了一种新颖的方法，它能从多视角image-pose pairs 中进行深度估计，其中模型还具有利用场景先前隐藏空间编码信息（ information from previous latent-space encodings of the scene）的能力。</p>
<p>模型使用成对的images-poses进行训练，他们通过encoder-decoder model 来进行视差估计。</p>
</blockquote>
<p>&emsp;&emsp;模型的创新点在哪里?</p>
<blockquote>
<p>通过a nonparametric Gaussian process prior 来软约束 the bottleneck layer。</p>
<p>提出了pose-kernel 结构,该结构encourages 相似的 poses  有类似的隐藏空间。</p>
<p>GP（Gaussian process ） prior的灵活性提供了adapting memory来融合之前views的信息。</p>
<p>end-to-end地共同训练encoder-decoder和GP超参数</p>
<p>还导出了一个能实时运行的轻型方案</p>
</blockquote>
<h3 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h3><p>&emsp;&emsp;什么是MVS问题？它有哪些变体和应用？</p>
<blockquote>
<p>MVS是指从具有已知姿势和内部参数的相机拍的图片中重建出3D场景结构的研究</p>
<p>变体：</p>
<ul>
<li>当motion已知时，从单目相机拍的视频中进行深度图估计</li>
<li>用传统双目惯导设备进行深度估计</li>
<li>从图片集中建立image-based3D模型</li>
</ul>
<p>应用：</p>
<ul>
<li>image-based 3D models  能用来测量和可视化大型环境来辅助设计和planning</li>
<li>深度估计对自主机器的感知和SLAM有利</li>
</ul>
</blockquote>
<p>&emsp;&emsp;我们的工作：</p>
<blockquote>
<p>我们的工作主要是对运动已知的单目相机拍的视频进行深度估计，In practice，运动可以用vio（visual-inertial odometry ）进行估，它能实时提供高精度的相机poses，漂移很小并且在手机上可以运行。</p>
</blockquote>
<p>&emsp;&emsp;为什么要做基于视频帧的深度估计而不是基于双目惯导设备？</p>
<blockquote>
<ul>
<li>在小型移动设备中，两个摄像头的baseline不能大，这限制了深度测量的范围。使用单目相机，其运动通常提供了一个比设备尺寸更大的baseline，这将提高远距离区域的测量精度</li>
<li>当相机在空间中旋转跳跃时，通常会从多个连续变化的views观察到相同的场景区域，因此能够有效融合所有这些信息来进行robust和stable的深度估计是有益的。</li>
</ul>
</blockquote>
<p>&emsp;&emsp;我们的方法：</p>
<blockquote>
<ul>
<li>我们提出了一种结合视差估计网络的新方法，该网络具有编码-解码器结构和plane-sweep cost量作为输入，还有一个GP在前面，which 软约束了bottleneck layer 来融合机油相似pose的视频帧信息。</li>
<li>a pose-kernel struct，为了有效改善重叠视图中信息的融合，与时间上的分离无关</li>
<li>既可用于batch mode 也可以 online mode，仅前面的帧会影响当前帧的预测</li>
</ul>
</blockquote>
<p>&emsp;&emsp;我们的贡献：</p>
<blockquote>
<ul>
<li>提出了一个MVS的新颖的方法，它将通过来自隐藏空间的先验概率传递先前重建的深度图信息。</li>
<li>对于non-parametric 隐藏空间，我们提出了pose-kernel方法，用于对观测帧之间影响相机姿态的先验知识进行编码。</li>
<li>证明了CNN encoder-decoder 结构和GP超参数可以一起训练</li>
<li>拓展了我们的方法使其可以在只能手机平板电脑中实时运行。</li>
</ul>
</blockquote>
<h3 id="Related-Work"><a href="#Related-Work" class="headerlink" title="Related Work"></a>Related Work</h3><p>&emsp;&emsp;略</p>
<h3 id="Methods"><a href="#Methods" class="headerlink" title="Methods"></a>Methods</h3><h4 id="1-网络结构"><a href="#1-网络结构" class="headerlink" title="1. 网络结构"></a>1. 网络结构</h4><p><img src="/2019/12/03/Multi-View-Stereo-by-Temporal-Nonparametric-Fusio/1.png" alt="1"></p>
<p><center>图1 网络结构图</center></p>
<blockquote>
<ul>
<li>我们方法由两部分组成</li>
<li>（图中的垂直数据流）CNN驱动的MVS方法，它将输入帧转变成成本量，然后通过编码器-解码器模型产生视差图（深度的倒数）。</li>
<li>（图中的水平数据流）通过在相机轨迹上传递有关隐藏空间的信息来耦合每个独立的视差预测任务。</li>
</ul>
</blockquote>
<p> &emsp;&emsp;对每个image-pair对，我们计算size为D*H*W的成本量，并连接参考的RGB图像作为编码器的输入，本文中的Img尺寸为320*256并且在0.5m-50m的inverse depth中均匀采样了D=64个深度平面。为了计算成本量，我们使用planar homography通过邻近平行帧在固定深度处将平行帧扭曲到参考帧。</p>
<script type="math/tex; mode=display">\mathbf{H}=\mathbf{K}(\mathbf{R}+t(\begin{matrix}0&0&\frac{1}{d_i}\end{matrix} ))\mathbf{K}^{-1}</script><p>$\mathbf{K}$是已知的intrinsics matrix,$(\mathbf{R},\mathbf{t})$是根据旋转矩阵相对于相邻帧的平移矢量给出的，$d_i$表示第i个虚拟平面的深度值，warped相邻帧与参考帧之间的绝对强度差被计算为每个深度平面上每个像素的代价：</p>
<script type="math/tex; mode=display">\mathbf{V}(d_i)=\sum_{R,G,B}{\widetilde{I_{d_i}}-I_r}</script><p>其中 $\widetilde{I_{d_i}}$ 代表通过 $d_i$ 深度平面的warped image，$I_r$代表参考帧。</p>
<p>在编码器中，由5个卷积层，编码后，我们得到一个大小为512*8*10的隐藏空间表示y，它将由GP模型转换得到，转换后的隐藏空间z表示，z作为解码端的输入，生成1*H*W的预测，编码器解码器之间有4个skip connection。所有卷积层之后都进行了Batch Normalization 和 Relu处理，预测层使用的sigmoid函数缩放了2来限制预测范围。为了支持任意输入，我们分别计算了每个相邻图像的成本量，然后对成本量求平均，再将其传到编码器-解码器网络。</p>
<p>在训练过程中，使用N个输入帧序列，我们通过将前一帧用作相邻帧（第一个帧将下一帧用作相邻帧）来预测N个深度图，并使用L1误差的均值 （at four scales）作为训练模型的总体损失。</p>
<h4 id="2-Pose-Kernel-Gaussian-process-prior"><a href="#2-Pose-Kernel-Gaussian-process-prior" class="headerlink" title="2. Pose-Kernel Gaussian process prior"></a>2. Pose-Kernel Gaussian process prior</h4><p>&emsp;&emsp;我们试图在潜在空间上定义一个概率先验来解释先验知识，即具有接近或重叠视野的pose应该比那些互相远离的pose或对着的pose产生更相似的隐藏空间编码。这个知识通过协方差（kernel）编码，因此我们需要定义距离度量或者在pose空间定义closeness的度量。</p>
<p><img src="/2019/12/03/Multi-View-Stereo-by-Temporal-Nonparametric-Fusio/4.png" alt="4"></p>
<p>其中姿势定义为$P=\{t,R\}$ 属于$R^3\times{SO(3)}$,<strong>I</strong>是一个单位矩阵，tr代表矩阵trace operator。</p>
<p>kernel设计：</p>
<p><img src="/2019/12/03/Multi-View-Stereo-by-Temporal-Nonparametric-Fusio/5.png" alt="5"></p>
<p>这个内核将两个任意相机姿态P，P′编码为nearness或者similarity in latent space。可学习超参数$\gamma^2$和ℓ定义了过程的特征量级和长度尺寸。</p>
<p>为了在帧中共享时间信息，我们为$z_i$中的所有值分配了独立的GP先验，并认为编码器输出的$y_i$是受噪声干扰的版本，该推断问题可以表示为一下GP回归模型：</p>
<p><img src="/2019/12/03/Multi-View-Stereo-by-Temporal-Nonparametric-Fusio/6.png" alt="6"></p>
<p><img src="/2019/12/03/Multi-View-Stereo-by-Temporal-Nonparametric-Fusio/7.png" alt="7"></p>
<p><img src="/2019/12/03/Multi-View-Stereo-by-Temporal-Nonparametric-Fusio/2.png" alt="2"></p>
<h4 id="Latent-state-batch-estimation"><a href="#Latent-state-batch-estimation" class="headerlink" title="Latent-state batch estimation"></a>Latent-state batch estimation</h4><p>&emsp; &emsp;似然是高斯函数，并且所有的GP共享相同的poses来评估协方差函数，因此我们可以使用一个矩阵求逆来解决512*8*10的 GP回归问题。这是由于后验协方差仅是输入姿势的函数，而不是图像的学习表示的值。</p>
<p><img src="/2019/12/03/Multi-View-Stereo-by-Temporal-Nonparametric-Fusio/8.png" alt="8"></p>
<p>covariance matrix  协方差矩阵</p>
<p>该批处理方案考虑了序列中所有相互关联的姿势，使其功能强大。 不利的一面是矩阵C随着输入帧/姿势的数量N的增长而增长，并且推理需要将矩阵求逆-矩阵大小按立方缩放。 因此，该方案仅适用于数百个帧的序列。</p>
<h4 id="Online-Estimation"><a href="#Online-Estimation" class="headerlink" title="Online Estimation"></a>Online Estimation</h4><p>&emsp;&emsp;当输入的图像姿势对有了时间顺序属性后，我们可以吧模型简化成一个directed graph。这种情况下，GP推理问题可以变成状态空间形式解决，每个姿态-帧的计算具有恒定的时间空间复杂度。我们通过下面过程可以精确地推论而无需近似。</p>
<p>&emsp;&emsp; 对于状态空间GP的推断，将协方差函数转换为dynamical模型， 选择初始状态作为协方差函数相对应的稳态</p>
<p><img src="/2019/12/03/Multi-View-Stereo-by-Temporal-Nonparametric-Fusio/9.png" alt="9"></p>
<p>我们共同推断所有独立GP的后验，以使其均值$u_i$ 为大小2*（512*8*10）的矩阵，其中列是 独立GPs的time-marginal means，二维状态来自于matern模型。协方差矩阵在所有的独立GP见共享。这使得推理很快。</p>
<p>我们定义了一个具有matern性质的演化算子</p>
<p><img src="/2019/12/03/Multi-View-Stereo-by-Temporal-Nonparametric-Fusio/10.png" alt="10"></p>
<p> consecutive  连贯的    propagated 传播</p>
<p>通过对当前step编码器输出$y_i$ 进行调节来给出后验均值和协方差:</p>
<p><img src="/2019/12/03/Multi-View-Stereo-by-Temporal-Nonparametric-Fusio/11.png" alt="11"></p>
<p> overloaded notation 符号重载       derivatives 导数</p>
<h3 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h3><p><img src="/2019/12/03/Multi-View-Stereo-by-Temporal-Nonparametric-Fusio/image-20191203205232123.png" alt="image-20191203205232123"></p>
<p><img src="/2019/12/03/Multi-View-Stereo-by-Temporal-Nonparametric-Fusio/image-20191203205339972.png" alt="image-20191203205339972"></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/12/02/Group-wise-Correlation-Stereo-Network/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="oooo">
      <meta itemprop="description" content="oooo的博客">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="oooo的博客">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2019/12/02/Group-wise-Correlation-Stereo-Network/" class="post-title-link" itemprop="url">Group-wise-Correlation-Stereo-Network</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-12-02 15:27:46" itemprop="dateCreated datePublished" datetime="2019-12-02T15:27:46+08:00">2019-12-02</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2019-12-03 14:19:02" itemprop="dateModified" datetime="2019-12-03T14:19:02+08:00">2019-12-03</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB/" itemprop="url" rel="index">
                    <span itemprop="name">文章阅读</span>
                  </a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="文章结构"><a href="#文章结构" class="headerlink" title="文章结构"></a>文章结构</h2><pre><code> 0. Abstract
 1. Introduction
 2. Related Work
 3. Group-Wise Correlation Network
 4. Experiment
 5. Conclusion
</code></pre><h2 id="文章解读"><a href="#文章解读" class="headerlink" title="文章解读"></a>文章解读</h2><h3 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h3><p>&emsp;&emsp;以前的工作中构建了跨越所有disparity levels的左右特征的 cross-correlation or concatenation的cost volumes，然后用2d或3d卷积神经网络来回归视差图。本文提出了用分组的方法来构建cost volumes。沿着channel dimension 左右特征被分成小组，然后在组之间计算correlation map，得到多匹配的cost proposals，然后打包成 cost volume。Group-wise 相关提供了度量特征相似性的有效表示，并且不会像full correlation丢失太多信息。</p>
<p>&emsp;&emsp;<a href="https://github.com/xy-guo/GwcNet" target="_blank" rel="noopener">代码链接</a></p>
<h3 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h3><p>&emsp;&emsp;<strong>传统的双目流程通常包含4步：</strong></p>
<ul>
<li>matching cost computation</li>
<li>cost aggregation</li>
<li>disparity optimization</li>
<li>postprocessing</li>
</ul>
<p>matching cost computation 是为了给左右图patches提供初始相似性度量。常见的matching cost 包括 绝对差（SAD）、平方差之和（SSD）、归一化互相关（NCC）</p>
<p>cost aggregation 和 optimization 包括上下文匹配成本和先验知识来得到更可靠的disparity预测</p>
<p>learning-base 的方法利用了不同的特征表示和聚类方法来计算matching costs。列举了几个网络和各自的方法。</p>
<p><strong>他们的缺点：</strong></p>
<blockquote>
<p>full correlation 丢失了很多信息因为它对每个disparity level只提供了一个单通道的相关图</p>
<p>concatenation volume 需要更多的参数从头学习相似性度量功能</p>
<p>hand-crafts的还在用传统的匹配成本，不能优化成端到端网络</p>
</blockquote>
<p><strong>我们的方法：</strong></p>
<blockquote>
<p>提取多级一元特征来构成左右图像对的高维度特征表示  fl , fr 。然后将特征沿着channel dimension进行分组。在所有disparity levels，第 i 个左特征组将与第 i 个右特征组相关联以获得group-wise的相关图，最后将所有相关图打包成一个4D成本量。</p>
<p>一元特征可视为groups of structed vectors，因此一个组的correlation maps 可以视为一个matching cost proposal </p>
</blockquote>
<p><strong>我们的主要贡献：</strong></p>
<blockquote>
<ul>
<li>提出了group-wise方法来构建cost volumes，提供了更好的相似性度量</li>
<li>改善了 the stacked 3D hourglass refinement network</li>
<li>在3个数据集上，比以前的方法有更好的性能</li>
<li>在限制聚合的计算成本时，性能降低小，在实时双目网络中有应用价值。</li>
</ul>
</blockquote>
<h3 id="Related-Work"><a href="#Related-Work" class="headerlink" title="Related Work"></a>Related Work</h3><p>&emsp;&emsp;略</p>
<h2 id="Group-wise-Correlation-Network"><a href="#Group-wise-Correlation-Network" class="headerlink" title="Group-wise Correlation Network"></a>Group-wise Correlation Network</h2><p>&emsp;&emsp;GwcNet是基于PSMNet，加入了group-wise correlation cost volume 和改进了 3d stacked hourglass network。</p>
<h4 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h4><p><img src="/2019/12/02/Group-wise-Correlation-Stereo-Network/1.png" alt="1"></p>
<center>Figure 1 GwcNet 流程图</center>
&emsp;&emsp;网络包含4个部分：一元特征提取、cost volume construction、 3d卷积聚合、 disparity预测。

> + cost volume 包含两个部分，concatenation volume 和group-wise correlation volume。
>
> + concatenation volume 是通过串联压缩后的左右特征来构建的
>
> + group-wise correlation volume 如下图所示



![2](2.png)

<center>Figure 2 3D聚合网络结构</center>



<p>&emsp;&emsp;<strong>网络前面是4个卷积，后面是3个堆叠的3d沙漏网络。</strong></p>
<p>&emsp;&emsp;特征提取采用了PSMNet里的ResNet-like 网络，它带有半拓展性，并且去掉了spatial pyramid pooling module。最后的conv2、conv3、conv4的特征图会被串成320-channel的一元特征图。</p>
<p>&emsp;&emsp;cost volume 由两部分组成：  a concatenation volume 和 a group-wise correlation volume。一元特征图会经过两次卷积压缩到12 channels到达concatenation volume。g-wcv会在下面具体讲到。这两个量会串联起来作为3D aggregation 网络的输入。</p>
<p>&emsp;&emsp;3D 聚合网络用来聚合相邻像素和视差的特征。如图2所示，前面的模块由4个具有 batch normalization and ReLU的3d卷积层组成。跟随的3个堆叠的3d沙漏网络通过encoder-decoder结构来修正低纹理和遮挡的情况。几个改进在下面会详细讲到。</p>
<h4 id="Group-wise-correlation-volume"><a href="#Group-wise-correlation-volume" class="headerlink" title="Group-wise correlation volume"></a>Group-wise correlation volume</h4><p>&emsp;&emsp;之前工作的问题：</p>
<blockquote>
<ul>
<li>cost volume是由不同视差level的左右特征关联或串联组成，它们都有缺点。</li>
<li>全关联提供了有效的方式来衡量特征相似度，但是丢失了很多信息，因为每个视差level它只产生了单通道的关联图。</li>
<li>串联量不包含特征相似的信息，因此网络需要更多参数来头学习特征相似度度量。</li>
</ul>
</blockquote>
<p>&emsp;&emsp;我们的group-wise correlation通过结合关联和串联量来解决问题。</p>
<script type="math/tex; mode=display">
\mathbf{C}_{gwc}(d,x,y,g)= \frac{1}{N_c/N_g}<\mathbf{f}^g_l(x,y),\mathbf{f}^g_r(x-d,y)></script><blockquote>
<ul>
<li>基本思想是把特征分组并且以组为单位计算correlation maps。</li>
<li>&lt;*,*&gt;表示内积，N<sub>c</sub>为一元特征的通道数，N<sub>g</sub>为组数，<strong>f</strong><sup>g</sup><sub>r</sub>为第g组右边的特征组，d为视差level。</li>
<li>然后所有的相关图打包为[D<sub>max</sub>/4, H/4, W/4, N<sub>g</sub>]形式的cost量。D<sub>max</sub>代表最大视差，D<sub>max</sub>/4代表特征最大视差。当N<sub>g</sub>为1时，分组关联就变成了全关联。</li>
</ul>
</blockquote>
<h4 id="Improved-3D-aggregation-module"><a href="#Improved-3D-aggregation-module" class="headerlink" title="Improved 3D aggregation module"></a>Improved 3D aggregation module</h4><p>&emsp;&emsp;我们对堆叠的沙漏架构进行了修改使其适合我们提出的分组相关性并提高了推理速度。</p>
<p><img src="/2019/12/02/Group-wise-Correlation-Stereo-Network/3.png" alt="3"></p>
<p><center>Figure 3 3D聚合结构表</center></p>
<blockquote>
<ul>
<li>在沙漏前模块之后添加了一个输出模块（Output Module 0）</li>
<li>移除了不同输出模块之间的剩余连接，因此可在推理期间移除辅助输出模块（0,1,2）</li>
<li>将1*1*1的3D卷积添加到每个沙漏模块内的快捷方式连接，图2中的虚线，在不增加大量计算成本的情况下提高性能。</li>
</ul>
</blockquote>
<h4 id="Output-module-and-loss-function"><a href="#Output-module-and-loss-function" class="headerlink" title="Output module and loss function"></a>Output module and loss function</h4><p>&emsp;&emsp;对于每个输出模块，采用两个3D卷积生成一个单通道的4D量，然后将这个量进行上采样并转换为沿视差维具有softmax性质的概率量。对于每个像素都有一个D<sub>max</sub> 长度的向量，其中包含所有视差level的概率p。然后视差估计为：</p>
<p><img src="/2019/12/02/Group-wise-Correlation-Stereo-Network/4.png" alt="4"></p>
<p>其中k代表可能的视差level，p<sub>k</sub>代表对应的概率。</p>
<p>输出的4个视差预测图表示为：</p>
<p><img src="/2019/12/02/Group-wise-Correlation-Stereo-Network/7.png" alt="7"></p>
<p>最后的loss表示为：</p>
<p><img src="/2019/12/02/Group-wise-Correlation-Stereo-Network/5.png" alt="5"></p>
<p><img src="/2019/12/02/Group-wise-Correlation-Stereo-Network/8.png" alt="8"></p>
<p>(打不出来那个数学符号就贴图了)。</p>
<p>coefﬁcients 系数</p>
<p><img src="/2019/12/02/Group-wise-Correlation-Stereo-Network/6.png" alt="6"></p>
<h3 id="Experiment"><a href="#Experiment" class="headerlink" title="Experiment"></a>Experiment</h3><p><img src="/2019/12/02/Group-wise-Correlation-Stereo-Network/9.png" alt="9"></p>
<p><img src="/2019/12/02/Group-wise-Correlation-Stereo-Network/10.png" alt="10"></p>
<p><img src="/2019/12/02/Group-wise-Correlation-Stereo-Network/11.png" alt="11"></p>
<h3 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h3><p>&emsp;&emsp;略。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

  </div>

  



          </div>
          

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">oooo</p>
  <div class="site-description" itemprop="description">oooo的博客</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">2</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
        <span class="site-state-item-count">1</span>
        <span class="site-state-item-name">分类</span>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">1</span>
        <span class="site-state-item-name">标签</span>
      </div>
  </nav>
</div>
  <div class="feed-link motion-element">
    <a href="/atom.xml" rel="alternate">
      <i class="fa fa-rss"></i>RSS
    </a>
  </div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/iamabadboy" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;iamabadboy" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">oooo</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v4.0.0
  </div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">主题 – <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> v7.5.0
  </div>

        












        
      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>
<script src="/js/utils.js"></script><script src="/js/motion.js"></script>
<script src="/js/schemes/pisces.js"></script>
<script src="/js/next-boot.js"></script>



  
















  

  
      
<script type="text/x-mathjax-config">
    MathJax.Ajax.config.path['mhchem'] = '//cdn.jsdelivr.net/npm/mathjax-mhchem@3';

  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$', '$'], ['\\(', '\\)'] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
        extensions: ['[mhchem]/mhchem.js'],
      equationNumbers: {
        autoNumber: 'AMS'
      }
    }
  });

  MathJax.Hub.Register.StartupHook('TeX Jax Ready', function() {
    MathJax.InputJax.TeX.prefilterHooks.Add(function(data) {
      if (data.display) {
        var next = data.script.nextSibling;
        while (next && next.nodeName.toLowerCase() === '#text') {
          next = next.nextSibling;
        }
        if (next && next.nodeName.toLowerCase() === 'br') {
          next.parentNode.removeChild(next);
        }
      }
    });
  });

  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for (i = 0; i < all.length; i += 1) {
      element = document.getElementById(all[i].inputID + '-Frame').parentNode;
      if (element.nodeName.toLowerCase() == 'li') {
        element = element.parentNode;
      }
      element.classList.add('has-jax');
    }
  });
</script>
<script>
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS-MML_HTMLorMML', () => {
    MathJax.Hub.Typeset();
  }, window.MathJax);
</script>

    

  

</body>
</html>
